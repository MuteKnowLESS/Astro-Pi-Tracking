{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_REFERENCE = 'earth_img\\photo_092_53245529093_o.jpg'\n",
    "IMAGE_COMPARISON = 'earth_img\\photo_091_53245728575_o.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_ransac(keypoints1, keypoints2, matches):\n",
    "    \"\"\"\n",
    "    Remove outliers using RANSAC to compute homography.\n",
    "    \"\"\"\n",
    "    src_pts = np.float32([keypoints1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    \n",
    "    # Calculate the Homography matrix with RANSAC\n",
    "    M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "    \n",
    "    return M, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1020\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'queryIdx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[99], line 55\u001b[0m\n\u001b[0;32m     52\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatches\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     53\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m---> 55\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[99], line 49\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(matches))\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m#matches = match_ratio(matches, 0.75)\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mremove_outliers_ransac\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkp1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkp2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatches\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     50\u001b[0m vis \u001b[38;5;241m=\u001b[39m draw_matches(image1_color, kp1, image2_color, kp2, matches)\n\u001b[0;32m     51\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(cv2\u001b[38;5;241m.\u001b[39mcvtColor(vis, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB))\n",
      "Cell \u001b[1;32mIn[98], line 5\u001b[0m, in \u001b[0;36mremove_outliers_ransac\u001b[1;34m(keypoints1, keypoints2, matches)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremove_outliers_ransac\u001b[39m(keypoints1, keypoints2, matches):\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m    Remove outliers using RANSAC to compute homography.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     src_pts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32([keypoints1[m\u001b[38;5;241m.\u001b[39mqueryIdx]\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m matches])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      6\u001b[0m     dst_pts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32([keypoints2[m\u001b[38;5;241m.\u001b[39mtrainIdx]\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m matches])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Calculate the Homography matrix with RANSAC\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[98], line 5\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremove_outliers_ransac\u001b[39m(keypoints1, keypoints2, matches):\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m    Remove outliers using RANSAC to compute homography.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     src_pts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32([keypoints1[\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqueryIdx\u001b[49m]\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m matches])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      6\u001b[0m     dst_pts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32([keypoints2[m\u001b[38;5;241m.\u001b[39mtrainIdx]\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m matches])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Calculate the Homography matrix with RANSAC\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'queryIdx'"
     ]
    }
   ],
   "source": [
    "def match_sift(image):\n",
    "    sift_detector = cv2.SIFT_create()\n",
    "    kp1, des1 = sift_detector.detectAndCompute(image, None)\n",
    "    return kp1, des1\n",
    "\n",
    "def match_bf(des1, des2):\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "    return matches\n",
    "\n",
    "def match_flann(des1, des2):\n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "    search_params = dict(checks=50)\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    matches = flann.knnMatch(des1, des2, k=2)\n",
    "    return matches\n",
    "\n",
    "def match_ratio(matches, ratio):\n",
    "    good = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < ratio * n.distance:\n",
    "            good.append(m)\n",
    "    return good\n",
    "\n",
    "def draw_matches(image1, kp1, image2, kp2, matches):\n",
    "    h1, w1 = image1.shape[:2]\n",
    "    h2, w2 = image2.shape[:2]\n",
    "    vis = np.zeros((max(h1, h2), w1 + w2, 3), np.uint8)\n",
    "    vis[:h1, :w1] = image1\n",
    "    vis[:h2, w1:w1 + w2] = image2\n",
    "    for m in matches:\n",
    "        pt1 = (int(kp1[m.queryIdx].pt[0]), int(kp1[m.queryIdx].pt[1]))\n",
    "        pt2 = (int(kp2[m.trainIdx].pt[0]) + w1, int(kp2[m.trainIdx].pt[1]))\n",
    "        cv2.line(vis, pt1, pt2, (0, 255, 0), 1)\n",
    "    return vis\n",
    "\n",
    "def main():\n",
    "    image1 = cv2.imread(IMAGE_COMPARISON, cv2.IMREAD_GRAYSCALE)\n",
    "    image2 = cv2.imread(IMAGE_REFERENCE, cv2.IMREAD_GRAYSCALE)\n",
    "    # Convert grayscale images to color\n",
    "    image1_color = cv2.cvtColor(image1, cv2.COLOR_GRAY2BGR)\n",
    "    image2_color = cv2.cvtColor(image2, cv2.COLOR_GRAY2BGR)\n",
    "    kp1, des1 = match_sift(image1)\n",
    "    kp2, des2 = match_sift(image2)\n",
    "    matches = match_bf(des1, des2)\n",
    "    print(len(matches))\n",
    "    #matches = match_ratio(matches, 0.75)\n",
    "    print(remove_outliers_ransac(kp1, kp2, matches))\n",
    "    vis = draw_matches(image1_color, kp1, image2_color, kp2, matches)\n",
    "    plt.imshow(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Matches\")\n",
    "    plt.show()\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Displacement Vector: dx=-27.69120998800236, dy=404.1618301572591\n",
      "Homography Matrix (M):\n",
      "[[9.67885196e-01 9.20412534e-03 4.35780287e+00]\n",
      " [2.69676391e-02 9.40814104e-01 4.10504534e+02]\n",
      " [4.82322516e-07 3.52460233e-06 1.00000000e+00]]\n",
      "Displacement Vector: dx=4.357802868561534, dy=410.5045344801554\n",
      "Number of Matches: 528\n",
      "Number of Inliers: 411\n",
      "Mean Displacement Vector: dx=-27.69120998800236, dy=404.1618301572591\n"
     ]
    }
   ],
   "source": [
    "def remove_outliers_ransac(keypoints1, keypoints2, matches):\n",
    "    \"\"\"\n",
    "    Remove outliers using RANSAC to compute homography.\n",
    "    \"\"\"\n",
    "    # Extract keypoints as float32\n",
    "    src_pts = np.float32([keypoints1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    \n",
    "    # Calculate the Homography matrix with RANSAC\n",
    "    M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "    matches_mask = mask.ravel().tolist()\n",
    "    \n",
    "    # Filter matches based on RANSAC mask (1 = inlier, 0 = outlier)\n",
    "    inliers = [m for i, m in enumerate(matches) if matches_mask[i]]\n",
    "\n",
    "    mean_displacement = []\n",
    "    \n",
    "    # Calculate the mean displacement vector for inliers\n",
    "    for m in inliers:\n",
    "        pt1 = keypoints1[m.queryIdx].pt\n",
    "        pt2 = keypoints2[m.trainIdx].pt\n",
    "        dx = pt2[0] - pt1[0]\n",
    "        dy = pt2[1] - pt1[1]\n",
    "        mean_displacement.append((dx, dy))\n",
    "\n",
    "    # Compute the mean displacement vector\n",
    "    mean_displacement = np.mean(mean_displacement, axis=0)\n",
    "\n",
    "    print(f\"Mean Displacement Vector: dx={mean_displacement[0]}, dy={mean_displacement[1]}\")\n",
    "\n",
    "    return M, inliers\n",
    "\n",
    "def match_sift(image):\n",
    "    sift_detector = cv2.SIFT_create()\n",
    "    kp1, des1 = sift_detector.detectAndCompute(image, None)\n",
    "    return kp1, des1\n",
    "\n",
    "def match_flann(des1, des2):\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "    search_params = dict(checks=50)\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    matches = flann.knnMatch(des1, des2, k=2)\n",
    "    return matches\n",
    "\n",
    "def lowe_ratio_test(matches, ratio=0.75):\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < ratio * n.distance:\n",
    "            good_matches.append(m)\n",
    "    return good_matches\n",
    "\n",
    "def match_bf(des1, des2):\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "    \n",
    "    # Keep only the best matches (the ones with the smallest distance)\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.75 * n.distance:\n",
    "            good_matches.append(m)\n",
    "    \n",
    "    return good_matches\n",
    "\n",
    "def draw_matches(image1, kp1, image2, kp2, matches):\n",
    "    h1, w1 = image1.shape[:2]\n",
    "    h2, w2 = image2.shape[:2]\n",
    "    vis = np.zeros((max(h1, h2), w1 + w2, 3), np.uint8)\n",
    "    vis[:h1, :w1] = image1\n",
    "    vis[:h2, w1:w1 + w2] = image2\n",
    "    for m in matches:\n",
    "        pt1 = (int(kp1[m.queryIdx].pt[0]), int(kp1[m.queryIdx].pt[1]))\n",
    "        pt2 = (int(kp2[m.trainIdx].pt[0]) + w1, int(kp2[m.trainIdx].pt[1]))\n",
    "        cv2.line(vis, pt1, pt2, (0, 255, 0), 1)\n",
    "    return vis\n",
    "\n",
    "def main():\n",
    "    image1 = cv2.imread(IMAGE_COMPARISON, cv2.IMREAD_GRAYSCALE)\n",
    "    image2 = cv2.imread(IMAGE_REFERENCE, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Preprocess the images and rescale\n",
    "    image1, img1_shape = preprocess_image(IMAGE_COMPARISON, scale_factor=0.5)\n",
    "    image2, img2_shape = preprocess_image(IMAGE_REFERENCE, scale_factor=0.5)\n",
    "\n",
    "    # Convert grayscale images to color for visualization\n",
    "    image1_color = cv2.cvtColor(image1, cv2.COLOR_GRAY2BGR)\n",
    "    image2_color = cv2.cvtColor(image2, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    # Detect keypoints using SIFT\n",
    "    kp1, des1 = match_sift(image1)\n",
    "    kp2, des2 = match_sift(image2)\n",
    "    \n",
    "    # Match the descriptors\n",
    "    matches = match_bf(des1, des2)\n",
    "    \n",
    "    # Apply RANSAC to remove outliers and compute homography\n",
    "    M, inliers = remove_outliers_ransac(kp1, kp2, matches)\n",
    "    \n",
    "    # Print the homography matrix for debugging\n",
    "    print(\"Homography Matrix (M):\")\n",
    "    print(M)\n",
    "    dx = M[0, 2]  # Horizontal translation\n",
    "    dy = M[1, 2]  # Vertical translation\n",
    "    print(f\"Displacement Vector: dx={dx}, dy={dy}\")\n",
    "\n",
    "    print(f\"Number of Matches: {len(matches)}\")\n",
    "    print(f\"Number of Inliers: {len(inliers)}\")\n",
    "\n",
    "    # calculate the mean displacement vector for inliers\n",
    "    mean_displacement = []\n",
    "    for m in inliers:\n",
    "        pt1 = kp1[m.queryIdx].pt\n",
    "        pt2 = kp2[m.trainIdx].pt\n",
    "        dx = pt2[0] - pt1[0]\n",
    "        dy = pt2[1] - pt1[1]\n",
    "        mean_displacement.append((dx, dy))\n",
    "    mean_displacement = np.mean(mean_displacement, axis=0)\n",
    "    print(f\"Mean Displacement Vector: dx={mean_displacement[0]}, dy={mean_displacement[1]}\")\n",
    "    \n",
    "    # Draw the matches between the two images\n",
    "    vis = draw_matches(image1_color, kp1, image2_color, kp2, inliers)\n",
    "    \n",
    "    # Show the matched image visualization\n",
    "    plt.imshow(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Matches\")\n",
    "    plt.show()\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This homography matrix, M, represents the 2D transformation from the reference image (keypoints1) to the target image (keypoints2).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using Brute force and Lowe Ratio with sift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "1020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x1ed82760280>, None)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "MIN_MATCH_COUNT = 10\n",
    "\n",
    "img1 = cv.imread('earth_img\\photo_091_53245728575_o.jpg',0)          # queryImage\n",
    "img2 = cv.imread('earth_img\\photo_092_53245529093_o.jpg',0) # trainImage\n",
    "\n",
    "# Initiate SIFT detector\n",
    "sift = cv.SIFT_create()\n",
    "\n",
    "# find the keypoints and descriptors with SIFT\n",
    "kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "\n",
    "bf = cv.BFMatcher()\n",
    "matches = bf.knnMatch(des1,des2, k=2)\n",
    "\n",
    "\n",
    "# store all the good matches as per Lowe's ratio test.\n",
    "good = []\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.7*n.distance:\n",
    "        good.append(m)\n",
    "\n",
    "print(len(good))\n",
    "print(len(matches))\n",
    "\n",
    "img3 = cv.drawMatches(img1,kp1,img2,kp2,good,None,flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "plt.imshow(img3),plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using FLANN and Lowe Ratio with sift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1020\n",
      "1020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x1ed84645ca0>, None)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "MIN_MATCH_COUNT = 10\n",
    "\n",
    "img1 = cv.imread('earth_img\\photo_091_53245728575_o.jpg',0)          # queryImage\n",
    "img2 = cv.imread('earth_img\\photo_092_53245529093_o.jpg',0) # trainImage\n",
    "\n",
    "# Initiate SIFT detector\n",
    "sift = cv.SIFT_create()\n",
    "\n",
    "# find the keypoints and descriptors with SIFT\n",
    "kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "\n",
    "# FLANN parameters\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks=100)   # or pass empty dictionary\n",
    "\n",
    "flann = cv.FlannBasedMatcher(index_params,search_params)\n",
    "\n",
    "matches = flann.knnMatch(des1,des2,k=2)\n",
    "\n",
    "# store all the good matches as per Lowe's ratio test.\n",
    "good = []\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.7*n.distance:\n",
    "        good.append(m)\n",
    "\n",
    "print(len(good))\n",
    "print(len(matches))\n",
    "\n",
    "img3 = cv.drawMatches(img1,kp1,img2,kp2,good,None,flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "plt.imshow(img3),plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set a condition that at least 10 matches (defined by MIN_MATCH_COUNT) are to be there to find the object. Otherwise simply show a message saying not enough matches are present.\n",
    "\n",
    "If enough matches are found, we extract the locations of matched keypoints in both the images. They are passed to find the perspective transformation. Once we get this 3x3 transformation matrix, we use it to transform the corners of queryImage to corresponding points in trainImage. Then we draw it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h, w:  3040 4056\n",
      "pst:  [[[   0.    0.]]\n",
      "\n",
      " [[   0. 3039.]]\n",
      "\n",
      " [[4055. 3039.]]\n",
      "\n",
      " [[4055.    0.]]]\n",
      "dts:  [[[  11.403623  826.8927  ]]\n",
      "\n",
      " [[  36.60615  3662.2334  ]]\n",
      "\n",
      " [[3937.8252   3763.2844  ]]\n",
      "\n",
      " [[3929.4214    928.07385 ]]]\n"
     ]
    }
   ],
   "source": [
    "if len(good)>MIN_MATCH_COUNT:\n",
    "    src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "    dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "    M, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC,5.0)\n",
    "    matchesMask = mask.ravel().tolist()\n",
    "    h,w = img1.shape\n",
    "    print(\"h, w: \", h,w)\n",
    "    pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "    print(\"pst: \", pts)\n",
    "    dst = cv.perspectiveTransform(pts,M)\n",
    "    print(\"dts: \", dst)\n",
    "    img2 = cv.polylines(img2,[np.int32(dst)],True,255,3, cv.LINE_AA)\n",
    "else:\n",
    "    print( \"Not enough matches are found - {}/{}\".format(len(good), MIN_MATCH_COUNT) )\n",
    "    matchesMask = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we draw our inliers (if successfully found the object) or matching keypoints (if failed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514\n",
      "1020\n",
      "514\n",
      "Mean Displacement Vector: dx=-64.67359035209923, dy=809.8123959938376\n",
      "Homography Matrix: [[ 9.66114712e-01  8.34490403e-03  1.14036224e+01]\n",
      " [ 2.49275749e-02  9.38174147e-01  8.26892685e+02]\n",
      " [-2.65250670e-08  1.41699668e-06  1.00000000e+00]]\n",
      "x =  11.403622437005497\n",
      "y =  826.8926850114964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x1ed82760310>, None)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "draw_params = dict(matchColor = (0,255,0), # draw matches in green color\n",
    "                   singlePointColor = None,\n",
    "                   matchesMask = matchesMask, # draw only inliers\n",
    "                   flags = 2)\n",
    "\n",
    "print(len(good))\n",
    "print(len(matches))\n",
    "print(len(matchesMask))\n",
    "\n",
    "displament_from_inliers = []\n",
    "for m in good:\n",
    "    pt1 = kp1[m.queryIdx].pt\n",
    "    pt2 = kp2[m.trainIdx].pt\n",
    "    dx = pt2[0] - pt1[0]\n",
    "    dy = pt2[1] - pt1[1]\n",
    "    displament_from_inliers.append((dx, dy))\n",
    "\n",
    "displament_from_inliers = np.mean(displament_from_inliers, axis=0)\n",
    "print(f\"Mean Displacement Vector: dx={displament_from_inliers[0]}, dy={displament_from_inliers[1]}\")\n",
    "\n",
    "print(\"Homography Matrix:\", M)\n",
    "\n",
    "print(\"x = \",M[0, 2])\n",
    "print(\"y = \",M[1, 2])\n",
    "\n",
    "\n",
    " \n",
    "img3 = cv.drawMatches(img1,kp1,img2,kp2,good,None,**draw_params)\n",
    " \n",
    "plt.imshow(img3, 'gray'),plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Convert Pixel Displacement to Camera Coordinates\n",
    "\n",
    "To relate the displacement in pixels to physical distances (in meters), you first need to convert pixel coordinates into camera coordinates. This can be done using the camera intrinsic matrix.\n",
    "\n",
    "Given a pixel displacement vector (dx,dy)(dx,dy), you can calculate the displacement in the camera's coordinate system using the following relations:\n",
    "\n",
    "delta X = dx/f_x\n",
    "\n",
    "delta Y = dy/f_y\n",
    "\n",
    "Where ΔX and ΔY are the displacement components in the camera's coordinate system (in meters).\n",
    "\n",
    "3. Depth Information\n",
    "\n",
    "To convert the displacement from camera coordinates to real-world coordinates (in meters), you also need depth information, which is the distance from the camera to the object in question. This step is necessary because the displacement in pixels corresponds to an angular displacement, which depends on the depth.\n",
    "\n",
    "If you have depth ZZ (in meters), the physical displacement can be calculated as:\n",
    "ΔXmeters=ΔX/Z\n",
    "\n",
    "ΔYmeters​=ΔY/z​\n",
    "\n",
    "Thus, the physical displacement in meters will depend on the depth ZZ, which could be obtained from stereo vision, a depth sensor, or assuming a known depth.\n",
    "\n",
    "### Notes\n",
    "\n",
    "- Focal Length: If you don’t have the focal length in pixels, you can estimate it from the camera's physical focal length and the sensor size. Focal length in pixels is calculated as:\n",
    "\n",
    "f_x = f_physical * image width / sensor width\n",
    "\n",
    "See camera calibration to get focal length\n",
    "\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS\n",
    "\n",
    "def get_focal_length(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    exif_data = img._getexif()\n",
    "    if exif_data:\n",
    "        for tag, value in exif_data.items():\n",
    "            if TAGS.get(tag) == \"FocalLength\":\n",
    "                return value\n",
    "    return None\n",
    "\n",
    "print(get_focal_length(\"your_image.jpg\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displacement in meters: dx=-10131.175331251332, dy=122533.1398548781\n",
      "Displacement in meters (Homography): dx=1786.3875763152873, dy=125117.56737576585\n",
      "Magnitude of Displacement: 122.95 km\n",
      "Magnitude of Displacement (Homography): 125.13 km\n"
     ]
    }
   ],
   "source": [
    "def pixel_to_meters(dx, dy, fx, fy, depth):\n",
    "    \"\"\"\n",
    "    Convert pixel displacement to real-world displacement in meters.\n",
    "    \n",
    "    Parameters:\n",
    "    - dx, dy: Pixel displacement\n",
    "    - fx, fy: Focal lengths in pixels (from intrinsic matrix)\n",
    "    - depth: Depth of scene (meters)\n",
    "    \n",
    "    Returns:\n",
    "    - (dx_meters, dy_meters): Displacement in meters\n",
    "    \"\"\"\n",
    "    dx_meters = (dx * depth) / fx\n",
    "    dy_meters = (dy * depth) / fy\n",
    "    return dx_meters, dy_meters\n",
    "\n",
    "FULL_FRAME_WIDTH = 4056 # pixels\n",
    "FULL_FRAME_HEIGHT = 3040 # pixels\n",
    "SENSOR_HIEGHT = 5.476 # mm\n",
    "SENSOR_WIDTH = 7.564 # mm\n",
    "FOCAL_LENGTH = 5 # mm\n",
    "\n",
    "FOCAL_X = FOCAL_LENGTH * (FULL_FRAME_WIDTH / SENSOR_WIDTH)\n",
    "FOCAL_Y = FOCAL_LENGTH * (FULL_FRAME_HEIGHT / SENSOR_HIEGHT)\n",
    "PRINCIPLE_POINT_X = FULL_FRAME_WIDTH / 2\n",
    "PRINCIPLE_POINT_Y = FULL_FRAME_HEIGHT / 2\n",
    "\n",
    "CAMERA_K = np.array([[FOCAL_X, 0, PRINCIPLE_POINT_X], \n",
    "              [0, FOCAL_Y, PRINCIPLE_POINT_Y], \n",
    "              [0, 0, 1]])\n",
    "\n",
    "DEPTH_Z = 420000 #(4.2e+05) meters\n",
    "\n",
    "dx_meters, dy_meters = pixel_to_meters(displament_from_inliers[0], displament_from_inliers[1], FOCAL_X, FOCAL_Y, DEPTH_Z)\n",
    "\n",
    "print(f\"Displacement in meters: dx={dx_meters}, dy={dy_meters}\")\n",
    "\n",
    "dx_meters_homography, dy_meters_homography = pixel_to_meters(M[0, 2], M[1, 2], FOCAL_X, FOCAL_Y, DEPTH_Z)\n",
    "\n",
    "print(f\"Displacement in meters (Homography): dx={dx_meters_homography}, dy={dy_meters_homography}\")\n",
    "\n",
    "# extract time difference between images using exif data\n",
    "\n",
    "\n",
    "# convert to kilometers and combine for magnitude\n",
    "magnitude = np.sqrt(dx_meters**2 + dy_meters**2) / 1000\n",
    "print(f\"Magnitude of Displacement: {magnitude:.2f} km\")\n",
    "\n",
    "magnitude_homography = np.sqrt(dx_meters_homography**2 + dy_meters_homography**2) / 1000\n",
    "print(f\"Magnitude of Displacement (Homography): {magnitude_homography:.2f} km\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: exif in c:\\users\\joshua moshal\\miniconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: plum-py<2.0.0,>=0.5.0 in c:\\users\\joshua moshal\\miniconda3\\lib\\site-packages (from exif) (0.8.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Time Difference: 0:00:16\n"
     ]
    }
   ],
   "source": [
    "%pip install exif\n",
    "\n",
    "from exif import Image\n",
    "from datetime import datetime\n",
    "\n",
    "def get_time(image):\n",
    "    with open(image, 'rb') as image_file:\n",
    "        img = Image(image_file)\n",
    "        time_str = img.get(\"datetime_original\")\n",
    "        time = datetime.strptime(time_str, '%Y:%m:%d %H:%M:%S')\n",
    "    return time\n",
    "\n",
    "time1 = get_time(IMAGE_COMPARISON)\n",
    "time2 = get_time(IMAGE_REFERENCE)\n",
    "time_diff = time2 - time1\n",
    "print(f\"Time Difference: {time_diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "velocity: 7.684453429929074 km/s\n",
      "velocity (Homography): 7.820644965860523 km/s\n"
     ]
    }
   ],
   "source": [
    "print(f\"velocity: {magnitude / time_diff.total_seconds()} km/s\")\n",
    "\n",
    "print(f\"velocity (Homography): {magnitude_homography / time_diff.total_seconds()} km/s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
